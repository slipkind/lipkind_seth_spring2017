{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- Learn and understand Zipf’s Law.\n",
    "- Pick any file (or files) in NLTK package.\n",
    "- Prove if Zipf’s Law works in Natural Language or not.\n",
    "- REQUIREMNTS: (Must Do)\n",
    "    - Use ’glob’ to open and read file. If read multiple files use LOOP to achieve.\n",
    "    - Create at least one function and one lambda function.\n",
    "    - Save your data as an CSV file contains (Word, Rank, Frequency) with TITLE and Sort it by RANK.\n",
    "    - Open your CSV file, generate a log-log figure according to the data you saved.\n",
    "    - Write a conclusion at the end of your code base on your figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import corpus # import corpus from nltk\n",
    "from glob import glob # import the glob module from glob\n",
    "from collections import Counter # import counter used in counting word frequency\n",
    "from string import digits # import digits to remove digits from any words\n",
    "import string\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readAndParseFiles(filepath):\n",
    "    \"\"\" Reads all files in the filepath, and preprocesses the data.\n",
    "    Input: filepath (str): The filepath where all files are located\n",
    "    Output: all_words (dict): The dictionary of words in all files plus the count\n",
    "    \"\"\"\n",
    "    all_words = dict()\n",
    "    my_list = list()\n",
    "    all_files = glob(filepath) # glob to list all files in the given path\n",
    "    no_punc = []\n",
    "    for filename in all_files:\n",
    "        myfile= open (filename,'r') # opens the file\n",
    "        line = myfile.read() # reads each line\n",
    "        line = line.replace('\\n','') # removes the new line character\n",
    "        line = line.translate(digits) # removes numbers for the text\n",
    "        line = line.lower() # turns string into lower case\n",
    "        words = [i.translate(string.punctuation) for i in line.split()] #takes out punctuation\n",
    "        my_list += words\n",
    "        my_list = list(filter(None, my_list)) # remove all empty strings\n",
    "        all_words = dict(Counter(my_list)) # Creates a dictionary of the number of times the word is in the list\n",
    "        myfile.close()\n",
    "        \n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dict = readAndParseFiles('c:/Users/Seth/AppData/Roaming/nltk_data/corpora/inaugural/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_list = sorted(my_dict.items(), key=lambda pair: pair[1], reverse=True) # sort in ascending order using lambda to get the frequency\n",
    "\n",
    "#print (sorted_list) # print list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv # import the csv module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 1\n",
    "with open('zipfs.csv', 'w', newline='') as csvfile: # open the csvfile as a writeable file\n",
    "    fieldname = ['word', 'rank', 'frequency']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldname) # uses dictWriter to make columns in the csv file\n",
    "\n",
    "    writer.writeheader()\n",
    "    for i in sorted_list: # for to search through each dict pair in the list\n",
    "        writer.writerow({'word': i[0], 'rank': counter, 'frequency': i[1]})\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zipfs law holds true in the inaugural module of nltk.corpus.  The graph shows that the most used words will show up about twice as often as the next word.  The outliers are towards the end of the graph, where many words are only used once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/zipfs.png'>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
